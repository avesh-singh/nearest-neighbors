{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric view of data\n",
    "\n",
    "As seen earlier, every input is just a collection of values pertaining to every feature. Thus, we can view each feature as a seperate dimension. Now we can start performing geometric operations on these inputs like Eucledian distance.\n",
    "Viewing input as vectors inherently assumes that features are not correlated to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting features into vectors\n",
    "\n",
    "- Trivial in case of `real valued features`\n",
    "- (0/1) in case of `binary features`\n",
    "- v-many binary indicator features for `categorical features`\n",
    "\n",
    "Explanation of last point: Suppose you want to convert a feature which conveys the color of a particular thing namely {RED, GREEN, BLUE, YELLOW}. If you map these values to {0,1,2,3} respectively, it conveys that RED is more similar to GREEN thann YELLOW which is not we wanted to say. All colors are equally dissimilar to each other. To convey this information, we need to convert a single valued feature into many-valued binary indicators namely {IsThisRed, IsThisGreen, IsThisBlue, IsThisYellow}.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "__Basic Idea__: Similar points have same labels.\n",
    "\n",
    "Common measure of similarity is Euclidean distance\n",
    "> $ \\large{d(a,b) = [\\sum^{D}_{d=1}(a_d - b_d)^2]^{1/2}}$\n",
    "\n",
    "There is no training in this algorithm. We just save all the examples given to us and when we are given the task of prediction, we let its k-nearest neighbours vote for the label it should have.\n",
    "\n",
    "__Inductive Bias__: Points with same label are always close to each other in term of euclidean distance.\n",
    "\n",
    "Despite its simplicity, this algorithm is _frustatingly effective_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What value should K take?\n",
    "\n",
    "K is what you call a __Hyperparameter__. This is a parameter which we have to decide apriori. This parameter cannot be learned through training on examples.\n",
    "\n",
    "Depth of a decision tree is a hyperparameter. You have to decide on it before beginning to train because algorithm will always favour an overfitting model(i.e. a tree which will have all of its input data points on leaves) because it reduces the training error.\n",
    "\n",
    "Here K is a hyperparameter. K denotes the number of nearest neighbors algorithm should look at to decide the output. This can only be figured out after training several times with different values of K and picking the model with minimum error on validation data.\n",
    "\n",
    "Small value of K leads to overfitting and large value of K leads to underfitting. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How does this algorithm treats features differently as compared to decision tree?\n",
    "\n",
    "When you find distance between two points in space, you treat all dimensions equally. All dimensions have equal say in the distance. This implies that in KNN all features have equal importance. \n",
    "\n",
    "On the other hand, main purpose of DT algorithm is to find most valuable features and let them decide the output.\n",
    "\n",
    "Based on above argument, if a dataset has only few relevant features and lots of irrelevant features, KNN will perform poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Boundaries\n",
    "\n",
    "A boundary between data points, derived from the trained model, which seperates points of different class. For eg. Suppose we have a line on a 2D plane above which all points have positive label and point with negative label below it. This line is the decision boundary derived from a simple linear model.\n",
    "\n",
    "<img src=\"assets/Various decision boundaries - KDNuggets.png\">\n",
    "\n",
    "### KNN\n",
    "\n",
    "<img src=\"assets/KNN decision boundary - stack exchange.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Demos\n",
    "\n",
    "- [KNN](https://lettier.com/projects/knearestneighbors/)\n",
    "- [Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import operator,random,math\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data src - https://www.kaggle.com/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_file_path = 'assets/diabetes.csv'\n",
    "diabetes_data = pd.read_csv(diabetes_file_path)\n",
    "del diabetes_data['SkinThickness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  Insulin   BMI  \\\n",
       "0            6      148             72        0  33.6   \n",
       "1            1       85             66        0  26.6   \n",
       "2            8      183             64        0  23.3   \n",
       "3            1       89             66       94  28.1   \n",
       "4            0      137             40      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(x,y,ratio=0.8):\n",
    "    count_train = int(x.shape[0]*ratio)\n",
    "    train_x = np.array(x[:count_train])\n",
    "    test_x = np.array(x[count_train:])\n",
    "    train_y = np.array(y[:count_train])\n",
    "    test_y = np.array(y[count_train:])\n",
    "    return (train_x,test_x,train_y,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data.sample(frac=1).reset_index(drop=True)\n",
    "labels = diabetes_data['Outcome']\n",
    "features = diabetes_data.drop(labels='Outcome',axis=1)\n",
    "train_x,test_x,train_y,test_y = split_train_test(features,labels,0.85)\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    labels = []\n",
    "    for inp in x:\n",
    "        # find distance of x from all points in training data\n",
    "        distances = [(math.sqrt(np.square(tx-inp).sum()),ty) for tx,ty in zip(train_x,train_y)]\n",
    "#         sort these distances\n",
    "        distances.sort(key=operator.itemgetter(0))\n",
    "        label = np.array([tup[1] for tup in distances[:k]]).sum()\n",
    "        if label*2 >= k:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "local = predict(test_x)\n",
    "accurate = 0\n",
    "for i in range(test_x.shape[0]):\n",
    "    if local[i] == test_y[i]:\n",
    "        accurate+=1\n",
    "print(accurate/test_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "model = KNC(n_neighbors=5,p=2,algorithm='brute')\n",
    "model.fit(train_x,train_y)\n",
    "lib = model.predict(test_x)\n",
    "accurate = 0\n",
    "for i in range(test_x.shape[0]):\n",
    "    if lib[i] == test_y[i]:\n",
    "        accurate+=1\n",
    "print(accurate/test_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 24.4 ms, total: 1.28 s\n",
      "Wall time: 336 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the implementation has predicted any label which does not match with library function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(x>0 for x in abs(local-lib))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
